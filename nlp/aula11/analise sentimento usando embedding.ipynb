{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b210f2-34bc-42f7-8fa3-5ad0a48f10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25af39c1-61b0-4118-a5ef-605dd95813f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e03e59f-f8cc-452b-95cd-b168b29ecc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b62e50-628a-4b2e-944f-fd8530fa721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a76e3d8-5a3d-4029-8f6e-c5bb5c7ae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d6ea84-79c7-4599-90d7-551f980e7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01141eaf-cd8b-4409-8777-d402f7d0b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b17ccf-8b9d-41b9-bae8-ed3758854ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "711d8f7b-59a2-44bc-ad7d-604780cdd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e19c060-1b79-4116-8827-6fb509da4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc4abce-cabe-4d87-97cf-caed93fbf8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1ada511-52fc-4897-8978-f5726b11277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7d7f92-5179-421d-9802-fdb6cd13dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KeyedVectors.load_word2vec_format(\"/git/dados/skip_s100/skip_s100.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801d6a5e-e2c1-4889-b372-9e0249fe5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ed6b688-4572-40e0-82eb-d9245b2bfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# textos = []\n",
    "# sentimentos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e884fec-581f-4abe-95e5-19211f85b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivo = open(\"../../../dados/nlp/news_sentiment_analysis.csv\", \"r\", encoding=\"utf-8\")\n",
    "# arquivo.readline()   # Descartando a primeira linha (header)\n",
    "# linha = arquivo.readline()\n",
    "# while linha != \"\":\n",
    "#     colunas = linha.split(\",\")\n",
    "#     texto = colunas[3]\n",
    "#     sentimento = colunas[6]\n",
    "#     textos.append(texto)\n",
    "#     sentimentos.append(sentimento)\n",
    "#     linha = arquivo.readline()\n",
    "# arquivo.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15d7a46f-240f-46d5-bde7-68cd62c20bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv(\"../../../dados/nlp/news_sentiment_analysis.csv\", sep=\",\", quotechar='\"', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1882403d-88e7-4043-af0f-413b3030bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = df_news[df_news['Sentiment'] != \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64a80f74-9bc5-4e8f-8801-77713ad22f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news[\"Sentiment_number\"] = df_news['Sentiment'].apply(lambda x: 0 if x == 'negative' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bfdc317-26a2-43e1-bc4d-23ce2137ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_news[\"description_lower\"] = df.news['Description'].apply(lambda x: x.lower())\n",
    "df_news[\"description_lower\"] = df_news['Description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0fe78fd-21b6-4aeb-a56d-2a2b66979773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords( texto ):\n",
    "    tokens = word_tokenize( texto )\n",
    "    nova_lista = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            # nova_lista.append(ps.stem(token))\n",
    "            nova_lista.append(token)\n",
    "    return \" \".join(nova_lista)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1480e6f8-1893-42fd-82fa-dab2fddd8248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st. george — kaitlyn larson, a first-year teacher at pine view high school, recently received the best in state award for a business leadership course. larson’s students in grades 10-12 had the highest passing rate on the youscience exam during the spring and fall semesters of 2023. the youscience exam is similar to final exams [&#8230;]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[\"description_lower\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60fd8a31-45d1-451a-b9d7-492288491a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news[\"description_stem\"] = df_news[\"description_lower\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b7c7485-609e-4efb-915c-9341b85bb295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       st. george — kaitlyn larson , first-year teach...\n",
       "2       ( marketscreener.com ) billionaire elon musk d...\n",
       "3       ( marketscreener.com ) u.s. trade regulator fr...\n",
       "4       4.5 million households u.s. solar panels homes...\n",
       "5       ( marketscreener.com ) billionaire investor ma...\n",
       "                              ...                        \n",
       "3493    qrg capital management inc. trimmed position s...\n",
       "3495    qrg capital management inc. increased stake sh...\n",
       "3496    qrg capital management inc. bought new positio...\n",
       "3497    qrg capital management inc. boosted stake akam...\n",
       "3499    qrg capital management inc. reduced holdings s...\n",
       "Name: description_stem, Length: 2711, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[\"description_stem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c241606-189c-4673-9f57-75b29f34df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vetorizador = CountVectorizer(max_features=2000)\n",
    "# vetorizador = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c81a1a-0da7-45b3-81a6-b1a1afe77209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_x = vetorizador.fit_transform(df_news[\"description_stem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f5755-36fc-490a-8f50-f7cc4c28308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulario = vetorizador.get_feature_names_out()\n",
    "# len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7e5d3e68-2e96-4b08-bc59-111a192f8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(bow_x, df_news[\"Sentiment_number\"], random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1da05b2e-2e5e-4896-8729-dc7ed65d599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_train = pd.DataFrame.sparse.from_spmatrix(x_train, columns=vocabulario)\n",
    "# one_hot_test = pd.DataFrame.sparse.from_spmatrix(x_test, columns=vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6e56fbe-38e7-47f2-8627-4b1f0134d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_to_embedding( texto ):\n",
    "    tokens = texto.split(\" \")\n",
    "    # modelo_padrao = modelo[\"desconhecido\"]\n",
    "    lista_embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in modelo:\n",
    "            lista_embeddings.append(modelo[token])\n",
    "    array_embeddings = np.array(lista_embeddings)\n",
    "    return [array_embeddings.sum()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8872098-46be-4498-99db-ea85879da7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto_to_embedding( df_news[\"description_stem\"][0] )\n",
    "df_news[\"description_final\"] = df_news[\"description_stem\"].apply(lambda x: texto_to_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c9ab9ad-51ac-4513-b053-8190b721b3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [36.74553]\n",
       "2        [67.08336]\n",
       "3       [41.691902]\n",
       "4       [105.82489]\n",
       "5        [72.46743]\n",
       "           ...     \n",
       "3493     [36.29739]\n",
       "3495     [42.85654]\n",
       "3496     [51.72785]\n",
       "3497    [41.106922]\n",
       "3499     [54.08328]\n",
       "Name: description_final, Length: 2711, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[\"description_final\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2617d8c3-ce0f-4396-8875-aa1fb1e24103",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_news[\"description_final\"], df_news[\"Sentiment_number\"], random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b17c1644-187f-4089-95de-3873fbdbe57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5864f45-9325-4e0b-8b13-0fc2ede02c4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1201\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1199\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1201\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1202\u001b[0m     X,\n\u001b[0;32m   1203\u001b[0m     y,\n\u001b[0;32m   1204\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1205\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1206\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1207\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1208\u001b[0m )\n\u001b[0;32m   1209\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1266\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1267\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1268\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1269\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1270\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1271\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1272\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1273\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1274\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1275\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mD:\\usr\\anaconda312\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8e9933b4-8232-401c-8949-dd0ff3e51d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9100294985250738"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(one_hot_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd64ed-a4d4-4049-b239-d1fe7e87b398",
   "metadata": {},
   "source": [
    "### Score com todas palavras do vocabulario ==> 0.9129793510324484\n",
    "### Score com 2000 palavras no vocabulario ==> 0.9174041297935103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86a7b6a0-359a-4fd2-bc65-803d53bdd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_vetorizador = CountVectorizer(vocabulary=vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a28a5d24-1238-4aab-acff-8c5c062b049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_x_predict = novo_vetorizador.fit_transform([\"The Baltimore Business Journal has hired Ben Terzi as its research editor. Terzi manages various databases to produce weekly Lists, the Book of Lists and other research projects for the Baltimore Business Journal. Prior to joining the Business Journal, he covered community news for The Dundalk Eagle and Avenue News. Born and raised in Baltimore, Terzi is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e02b5956-be35-400c-ab46-e6abb1e794ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = pd.DataFrame.sparse.from_spmatrix(bow_x_predict, columns=vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24439e63-2892-47b1-a758-e46f8fbcc3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fc221-0a25-4d0e-9c62-fb637d7c4ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
